{% extends "base.html" %}

{% block title %}AI Conversation{% endblock %}

{% block content %}
<div class="bg-white rounded-3xl shadow-2xl max-w-4xl mx-auto overflow-hidden">
    <!-- Header Section -->
    <div class="bg-gradient-to-r from-primary-dark via-[#9c27b0] to-primary-dark text-white p-8">
        <div class="flex justify-between items-center mb-4">
            <div>
                <h1 class="text-4xl font-extrabold mb-2 tracking-tight text-white">üí¨ Talk with SymbiONE</h1>
                <p class="text-white/90 m-0 text-lg">
                    Have a natural conversation about your career, job search, or wellness. 
                    I'm here to help with advice, support, and guidance.
                </p>
            </div>
            <div id="connectionStatus" class="flex items-center gap-2 px-5 py-2.5 bg-white/20 backdrop-blur-sm rounded-full text-sm text-white font-semibold border border-white/30">
                <span id="statusDot" class="w-3 h-3 bg-white rounded-full inline-block animate-pulse"></span>
                <span id="statusText">Live</span>
            </div>
        </div>
    </div>

    <!-- Conversation Area -->
    <div class="p-8">
    <div id="conversationArea" class="bg-gray-50 rounded-2xl p-5 min-h-[400px] max-h-[500px] overflow-y-auto mb-5 border-2 border-gray-200 scroll-smooth">
        <div id="messagesContainer">
            {% if conversation_history %}
                {% for role, message in conversation_history %}
                    <div class="mb-4 p-4 rounded-xl {% if role == 'user' %}bg-gradient-to-r from-primary/10 to-primary-dark/10 ml-auto max-w-[80%] border-l-4 border-primary-dark{% else %}bg-gradient-to-r from-primary/5 to-primary-dark/5 mr-auto max-w-[80%] border-l-4 border-primary{% endif %}">
                        <div class="text-xs opacity-80 mb-2">
                            {% if role == 'user' %}
                                <strong>üë§ You</strong>
                            {% else %}
                                <strong>ü§ñ SymbiONE</strong>
                            {% endif %}
                        </div>
                        <div class="text-[15px] leading-relaxed break-words">{{ message }}</div>
                    </div>
                {% endfor %}
            {% else %}
                <div class="text-center text-gray-600 p-8">
                    <p class="mb-4">üëã Hi! I'm SymbiONE. I can help you with:</p>
                    <ul class="text-left inline-block my-4 space-y-2">
                        <li>Career advice and job search tips</li>
                        <li>Wellness support during your job search</li>
                        <li>Understanding your skills and career path</li>
                        <li>Answering questions about finding jobs</li>
                    </ul>
                    <p class="mt-4">Start by saying hello or asking me anything!</p>
                </div>
            {% endif %}
        </div>
    </div>

    <!-- Input Area -->
    <div class="input-area">
        <div class="flex gap-3 items-center">
            <textarea 
                id="messageInput" 
                placeholder="Type your message here or click the microphone to speak..."
                rows="2"
                class="flex-1 p-4 border-2 border-gray-300 rounded-xl text-base font-inherit resize-y min-h-[50px] focus:border-primary focus:outline-none focus:ring-2 focus:ring-primary/20"
            ></textarea>
            
            <button id="voiceButton" onclick="toggleVoiceRecording()" 
                    class="w-[60px] h-[60px] rounded-full border-none bg-gradient-to-r from-primary to-primary-dark text-white text-2xl cursor-pointer shadow-lg hover:shadow-xl transition-all duration-300 hover:-translate-y-1"
                    title="Click to start voice recording">
                üé§
            </button>
            
            <button id="stopButton" onclick="stopSpeaking()" 
                    class="hidden w-[60px] h-[60px] rounded-full border-none bg-gradient-to-r from-red-500 to-red-700 text-white text-2xl cursor-pointer shadow-lg hover:shadow-xl transition-all duration-300 animate-pulse"
                    title="Stop AI from speaking">
                ‚èπÔ∏è
            </button>
            
            <button id="sendButton" onclick="sendMessage()" 
                    class="px-8 py-4 bg-gradient-to-r from-primary to-primary-dark text-white border-none rounded-xl text-base font-semibold cursor-pointer shadow-lg hover:shadow-xl hover:-translate-y-1 transition-all duration-300"
                    title="Send message">
                Send
            </button>
        </div>
        
        <div class="flex gap-3 mt-3 justify-between items-center">
            <div class="flex gap-4 items-center flex-wrap">
                <div id="voiceStatus" class="text-gray-600 text-sm"></div>
                <label class="flex items-center gap-2 text-sm text-gray-600 cursor-pointer">
                    <input type="checkbox" id="voiceOnlyMode" checked onchange="toggleVoiceOnlyMode()"
                           class="w-[18px] h-[18px] cursor-pointer">
                    <span>üé§ Voice-Only Mode (Voice Input ‚Üí AI Voice Output)</span>
                </label>
                <label class="flex items-center gap-2 text-sm text-gray-600 cursor-pointer">
                    <input type="checkbox" id="streamingMode" checked 
                           class="w-[18px] h-[18px] cursor-pointer">
                    <span>‚ú® Live Streaming (Real-time from Gemini)</span>
                </label>
            </div>
            <button onclick="clearConversation()" 
                    class="px-4 py-2 bg-gray-100 text-gray-600 border border-gray-300 rounded-lg text-sm cursor-pointer hover:bg-gray-200 transition-colors duration-200">
                üóëÔ∏è Clear Chat
            </button>
        </div>
    </div>

    <!-- Quick Actions -->
    <div class="mt-8 p-5 bg-gradient-to-r from-primary/10 to-primary-dark/10 rounded-2xl">
        <h3 class="mt-0 text-primary text-xl font-semibold mb-3">üí° Quick Questions</h3>
        <div class="flex flex-wrap gap-3">
            <button onclick="sendQuickMessage('How can I improve my resume?')" 
                    class="px-5 py-3 bg-white border-2 border-primary text-primary rounded-lg text-sm font-semibold cursor-pointer transition-all duration-300 hover:bg-primary hover:text-white hover:-translate-y-0.5 hover:shadow-md">üìÑ Resume Tips</button>
            <button onclick="sendQuickMessage('I feel stressed about job searching. Any advice?')" 
                    class="px-5 py-3 bg-white border-2 border-primary text-primary rounded-lg text-sm font-semibold cursor-pointer transition-all duration-300 hover:bg-primary hover:text-white hover:-translate-y-0.5 hover:shadow-md">üßò Stress Help</button>
            <button onclick="sendQuickMessage('What skills should I learn for tech jobs?')" 
                    class="px-5 py-3 bg-white border-2 border-primary text-primary rounded-lg text-sm font-semibold cursor-pointer transition-all duration-300 hover:bg-primary hover:text-white hover:-translate-y-0.5 hover:shadow-md">üõ†Ô∏è Skill Advice</button>
            <button onclick="sendQuickMessage('How do I prepare for job interviews?')" 
                    class="px-5 py-3 bg-white border-2 border-primary text-primary rounded-lg text-sm font-semibold cursor-pointer transition-all duration-300 hover:bg-primary hover:text-white hover:-translate-y-0.5 hover:shadow-md">üéØ Interview Prep</button>
        </div>
    </div>
    </div>
</div>

<script>
// Speech Recognition Setup
let recognition = null;
let isRecording = false;
let isSpeaking = false;
let continuousVoiceMode = false;
let voiceOnlyMode = true; // Default to voice-only mode
let currentStreamingMessage = null;
let lastFinalTranscript = ''; // Track processed transcripts to avoid duplicates
let pendingTranscript = ''; // Track interim results
let autoSendTimeout = null; // For auto-sending in real-time mode
let isProcessingMessage = false; // Prevent sending multiple messages simultaneously
let currentUtterance = null; // Track current TTS utterance
let lastUpdateTime = 0; // For throttling UI updates

// Initialize Speech Recognition with optimized settings
const UPDATE_THROTTLE = 100; // Throttle UI updates to 100ms for performance

if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = true; // Enable interim results for live transcription
    recognition.lang = 'en-US';
    recognition.maxAlternatives = 1; // Improve performance by only getting best match
    
    recognition.onresult = function(event) {
        const input = document.getElementById('messageInput');
        const now = Date.now();
        
        // Throttle interim result updates to reduce lag
        const isInterimUpdate = now - lastUpdateTime < UPDATE_THROTTLE;
        
        let finalText = '';
        let interimText = '';
        
        // Process all results efficiently
        for (let i = event.resultIndex; i < event.results.length; i++) {
            const result = event.results[i];
            const transcript = result[0].transcript;
            
            if (result.isFinal) {
                // Only add final transcripts once
                if (!lastFinalTranscript.includes(transcript.trim())) {
                    finalText += transcript + ' ';
                    lastFinalTranscript += transcript + ' ';
                }
            } else {
                // Store latest interim result
                interimText = transcript;
            }
        }
        
        // Update input field efficiently with minimal DOM manipulation
        if (finalText || (!isInterimUpdate && interimText)) {
            // Efficiently build new value
            let newValue = '';
            
            // Get base value (remove old interim transcript if exists)
            let baseValue = input.value;
            if (pendingTranscript) {
                const pendingIndex = baseValue.lastIndexOf(pendingTranscript);
                if (pendingIndex !== -1) {
                    baseValue = baseValue.substring(0, pendingIndex).trim();
                }
            }
            
            // Combine: base + new final text + new interim text
            if (baseValue) {
                newValue = baseValue + (finalText ? ' ' + finalText.trim() : '');
            } else {
                newValue = finalText.trim();
            }
            
            if (interimText && !isInterimUpdate) {
                newValue += (newValue ? ' ' : '') + interimText;
            }
            
            newValue = newValue.trim();
            
            // Only update DOM if value actually changed (prevents unnecessary reflows)
            if (input.value !== newValue) {
                // Use requestAnimationFrame for smooth UI updates
                requestAnimationFrame(() => {
                    input.value = newValue;
                });
                pendingTranscript = interimText || '';
                lastUpdateTime = now;
            }
            
            // Update status less frequently (throttled)
            if (finalText && !isInterimUpdate) {
                document.getElementById('voiceStatus').textContent = '‚úì Transcribed';
            } else if (interimText && !isInterimUpdate) {
                document.getElementById('voiceStatus').textContent = 'üé§ Listening...';
            }
        }
        
        // Handle auto-send for final transcripts
        if (finalText.trim() && !isProcessingMessage) {
            // Clear any pending auto-send timeout
            if (autoSendTimeout) {
                clearTimeout(autoSendTimeout);
            }
            
            // In voice-only or continuous mode: auto-send after speech is finalized
            if (voiceOnlyMode || continuousVoiceMode) {
                const delay = voiceOnlyMode ? 500 : 800; // Slightly longer delay to ensure complete transcription
                autoSendTimeout = setTimeout(() => {
                    const message = input.value.trim();
                    if (message && !isProcessingMessage && !isSpeaking) {
                        // Stop listening while processing
                        if (isRecording) {
                            recognition.stop();
                            isRecording = false;
                            updateVoiceButton();
                        }
                        sendMessage();
                        // Reset tracking for next utterance
                        lastFinalTranscript = '';
                        pendingTranscript = '';
                    }
                }, delay);
            } else {
                // Single mode: stop recording after final transcript
                isRecording = false;
                updateVoiceButton();
            }
        }
    };
    
    recognition.onerror = function(event) {
        console.error('Speech recognition error:', event.error);
        
        // Handle common errors gracefully
        if (event.error === 'no-speech') {
            // This is normal, just wait for speech
            return;
        } else if (event.error === 'audio-capture') {
            document.getElementById('voiceStatus').textContent = '‚ùå No microphone found';
        } else if (event.error === 'not-allowed') {
            document.getElementById('voiceStatus').textContent = '‚ùå Microphone permission denied';
        } else {
            document.getElementById('voiceStatus').textContent = '‚ùå Error: ' + event.error;
        }
        
        // Only stop if not in continuous mode
        if (!continuousVoiceMode && !voiceOnlyMode) {
            isRecording = false;
            updateVoiceButton();
        } else if (voiceOnlyMode || continuousVoiceMode) {
            // In continuous mode, try to restart after error
            setTimeout(() => {
                if ((voiceOnlyMode || continuousVoiceMode) && !isRecording && !isProcessingMessage) {
                    try {
                        recognition.start();
                        isRecording = true;
                        updateVoiceButton();
                    } catch (e) {
                        console.log('Recognition restart after error failed:', e);
                    }
                }
            }, 1000);
        }
    };
    
    recognition.onend = function() {
        // Only clear pending transcript if we're not expecting more input
        if (!continuousVoiceMode && !voiceOnlyMode) {
            const input = document.getElementById('messageInput');
            if (pendingTranscript) {
                // If we have a pending interim, convert it to final
                const finalValue = input.value.replace(pendingTranscript, '').trim();
                input.value = finalValue;
                pendingTranscript = '';
            }
        }
        
        // Auto-restart logic for continuous modes
        if ((voiceOnlyMode || continuousVoiceMode) && !isSpeaking && !isProcessingMessage) {
            // In voice-only mode, wait for AI to finish speaking (handled by TTS callback)
            // For non-voice-only continuous mode, restart after delay
            if (!voiceOnlyMode) {
                setTimeout(() => {
                    if (continuousVoiceMode && !isSpeaking && !isProcessingMessage && !isRecording) {
                        try {
                            lastFinalTranscript = ''; // Reset for next utterance
                            recognition.start();
                            isRecording = true;
                            updateVoiceButton();
                        } catch (e) {
                            // Recognition might already be starting, ignore
                            console.log('Recognition restart skipped:', e.message);
                        }
                    }
                }, 500);
            }
        } else if (isRecording && !voiceOnlyMode && !continuousVoiceMode) {
            // Single mode: stop recording
            document.getElementById('voiceStatus').textContent = 'Stopped recording';
            isRecording = false;
            updateVoiceButton();
        }
    };
    
    // Optimize recognition start
    recognition.onstart = function() {
        console.log('Speech recognition started');
        lastFinalTranscript = '';
        pendingTranscript = '';
        lastUpdateTime = 0; // Reset throttle timer
    };
} else {
    document.getElementById('voiceButton').style.display = 'none';
}

// Note: Continuous voice mode is automatically enabled when voice-only mode is on
// This function is kept for backwards compatibility but is no longer used directly

// Store selected female voice in localStorage for persistence
const VOICE_STORAGE_KEY = 'symbione_selected_female_voice';
const VOICE_STORAGE_LANG = 'symbione_selected_female_voice_lang';
const VOICE_STORAGE_HINDI_KEY = 'symbione_selected_hindi_female_voice';
const VOICE_STORAGE_HINDI_LANG = 'symbione_selected_hindi_female_voice_lang';

// Detect if text contains Hindi characters
function isHindiText(text) {
    if (!text) return false;
    // Hindi Unicode range: \u0900-\u097F
    const hindiPattern = /[\u0900-\u097F]/;
    return hindiPattern.test(text);
}

// Get the best available Hindi female voice
// FIXED: Always uses saved voice if available, only selects new one if saved voice is not found
function getBestHindiFeminineVoice() {
    const voices = window.speechSynthesis.getVoices();
    
    if (!voices || voices.length === 0) {
        console.warn('No voices available');
        return null;
    }
    
    // ALWAYS check saved Hindi voice first (persistent across sessions)
    const savedVoiceName = localStorage.getItem(VOICE_STORAGE_HINDI_KEY);
    const savedVoiceLang = localStorage.getItem(VOICE_STORAGE_HINDI_LANG);
    
    if (savedVoiceName && savedVoiceLang) {
        const savedVoice = voices.find(v => 
            v.name === savedVoiceName && v.lang === savedVoiceLang
        );
        if (savedVoice) {
            console.log('‚úì Using saved Hindi female voice (FIXED):', savedVoice.name);
            return savedVoice; // Always return saved voice if found - NO RE-SELECTION
        } else {
            // Saved voice no longer available, will select new one
            console.log('‚ö† Saved Hindi voice no longer available, will select new one and save it');
        }
    }
    
    // List of known Hindi female voice names
    const hindiVoiceNames = [
        'Veena',                 // macOS (Indian accent, supports Hindi)
        'Google ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä - Female',
        'Microsoft Ravi',        // Hindi male, but check for female
        'Microsoft Hemant'       // Hindi, check for female variant
    ];
    
    // First priority: Find Hindi voices by exact name match
    for (const hindiName of hindiVoiceNames) {
        const voice = voices.find(v => {
            const name = v.name.toLowerCase();
            const lang = v.lang.toLowerCase();
            return (lang.includes('hi') || lang.includes('hindi') || lang.includes('in')) &&
                   (name.includes(hindiName.toLowerCase()) || name.includes('hindi') || name.includes('veena'));
        });
        if (voice) {
            // FIXED: Save this Hindi voice preference permanently and NEVER change it
            localStorage.setItem(VOICE_STORAGE_HINDI_KEY, voice.name);
            localStorage.setItem(VOICE_STORAGE_HINDI_LANG, voice.lang);
            console.log('‚úì Selected NEW Hindi female voice (SAVED FOREVER):', voice.name);
            console.log('  ‚ö†Ô∏è This Hindi voice will be used in ALL future sessions until manually changed');
            return voice;
        }
    }
    
    // Second priority: Look for any voice with Hindi language code (hi, hi-IN, etc.)
    const hindiVoices = voices.filter(v => {
        const lang = v.lang.toLowerCase();
        return lang.includes('hi') || lang.includes('hindi') || lang.includes('in-in');
    });
    
    if (hindiVoices.length > 0) {
        // Prefer female voices
        const femaleHindi = hindiVoices.find(v => {
            const name = v.name.toLowerCase();
            return name.includes('female') || 
                   name.includes('woman') || 
                   name.includes('veena');
        }) || hindiVoices[0];
        
        // FIXED: Save this Hindi voice preference permanently
        localStorage.setItem(VOICE_STORAGE_HINDI_KEY, femaleHindi.name);
        localStorage.setItem(VOICE_STORAGE_HINDI_LANG, femaleHindi.lang);
        console.log('‚úì Selected Hindi voice (SAVED FOREVER):', femaleHindi.name);
        return femaleHindi;
    }
    
    // Fallback: Use Veena if available (macOS Indian voice that can handle Hindi)
    const veenaVoice = voices.find(v => 
        v.name.toLowerCase().includes('veena')
    );
    if (veenaVoice) {
        // FIXED: Save this Hindi voice preference permanently
        localStorage.setItem(VOICE_STORAGE_HINDI_KEY, veenaVoice.name);
        localStorage.setItem(VOICE_STORAGE_HINDI_LANG, veenaVoice.lang);
        console.log('‚úì Using Veena voice for Hindi (SAVED FOREVER):', veenaVoice.name);
        return veenaVoice;
    }
    
    console.warn('‚ö† No Hindi voice found, may use default voice');
    return null;
}

// Get the best available female voice - explicitly selects only female voices
// FIXED: Always uses saved voice if available, only selects new one if saved voice is not found
function getBestFeminineVoice(isHindi = false) {
    const voices = window.speechSynthesis.getVoices();
    
    if (!voices || voices.length === 0) {
        console.warn('No voices available');
        return null;
    }
    
    // Determine which storage keys to use based on language
    const storageKey = isHindi ? VOICE_STORAGE_HINDI_KEY : VOICE_STORAGE_KEY;
    const storageLang = isHindi ? VOICE_STORAGE_HINDI_LANG : VOICE_STORAGE_LANG;
    
    // ALWAYS check saved voice first (persistent across sessions)
    const savedVoiceName = localStorage.getItem(storageKey);
    const savedVoiceLang = localStorage.getItem(storageLang);
    
    if (savedVoiceName && savedVoiceLang) {
        // Try to find the saved voice first (permanent preference)
        const savedVoice = voices.find(v => 
            v.name === savedVoiceName && v.lang === savedVoiceLang
        );
        if (savedVoice) {
            console.log(`‚úì Using saved ${isHindi ? 'Hindi' : 'English'} female voice (FIXED):`, savedVoice.name);
            return savedVoice; // Always return saved voice if found - NO RE-SELECTION
        } else {
            // Saved voice no longer available, but keep trying to find a similar one
            console.log('‚ö† Saved voice no longer available, will select new one and save it');
            // Don't clear here - we'll select a new one and save it
        }
    }
    
    // If Hindi is requested and no saved voice, get Hindi voice
    if (isHindi) {
        const hindiVoice = getBestHindiFeminineVoice();
        if (hindiVoice) {
            return hindiVoice; // This will be saved by getBestHindiFeminineVoice
        }
        // Fallback to English voice if no Hindi voice found
        return getBestFeminineVoice(false);
    }
    
    // Only select new voice if no saved voice exists or saved voice is unavailable
    // This ensures we NEVER change voices once one is selected and saved
    
    // List of known female voice names (varies by OS/browser) - priority order
    const femaleVoiceNames = [
        'Samantha',              // macOS (natural, soft, feminine) - HIGHEST PRIORITY
        'Karen',                 // macOS (warm, feminine)
        'Victoria',              // macOS (clear, feminine)
        'Fiona',                 // macOS
        'Moira',                 // macOS (Irish accent)
        'Tessa',                 // macOS (South African accent)
        'Zira',                  // Windows/Edge (female)
        'Hazel',                 // Windows/Edge (British female)
        'Google US English - Female',
        'Google UK English - Female',
        'Microsoft Zira',
        'Microsoft Hazel'
    ];
    
    // First priority: Find voices by exact name match (most reliable)
    for (const femaleName of femaleVoiceNames) {
        const voice = voices.find(v => {
            const name = v.name.toLowerCase();
            return name === femaleName.toLowerCase() || 
                   name.includes(femaleName.toLowerCase()) ||
                   (name.includes('samantha') && !name.includes('male')) ||
                   (name.includes('karen') && !name.includes('male')) ||
                   (name.includes('victoria') && !name.includes('male')) ||
                   (name.includes('fiona') && !name.includes('male')) ||
                   (name.includes('zira')) ||
                   (name.includes('hazel'));
        });
        if (voice) {
            // FIXED: Save this voice preference permanently and NEVER change it
            localStorage.setItem(storageKey, voice.name);
            localStorage.setItem(storageLang, voice.lang);
            console.log(`‚úì Selected NEW ${isHindi ? 'Hindi' : 'English'} female voice (SAVED FOREVER):`, voice.name);
            console.log(`  ‚ö†Ô∏è This voice will be used in ALL future sessions until manually changed`);
            return voice;
        }
    }
    
    // Second priority: Look for any voice explicitly marked as "female" or "woman"
    const explicitFemale = voices.find(v => {
        const name = v.name.toLowerCase();
        return name.includes('female') || 
               name.includes('woman') ||
               name.includes('girl');
    });
    if (explicitFemale) {
        // FIXED: Save this voice preference permanently
        localStorage.setItem(storageKey, explicitFemale.name);
        localStorage.setItem(storageLang, explicitFemale.lang);
        console.log(`‚úì Selected explicit ${isHindi ? 'Hindi' : 'English'} female voice (SAVED FOREVER):`, explicitFemale.name);
        return explicitFemale;
    }
    
    // Third priority: Filter out known male voices and select from remaining
    const knownMaleVoices = ['male', 'daniel', 'alex', 'tom', 'david', 'james', 'john'];
    const nonMaleVoices = voices.filter(v => {
        const name = v.name.toLowerCase();
        return !knownMaleVoices.some(male => name.includes(male)) &&
               v.lang.startsWith('en');
    });
    
    if (nonMaleVoices.length > 0) {
        // Prioritize voices with higher-pitched characteristics
        const bestVoice = nonMaleVoices.find(v => 
            v.name.includes('Enhanced') || 
            v.name.includes('Premium') ||
            v.name.includes('Natural')
        ) || nonMaleVoices[0];
        
        // FIXED: Save this voice preference permanently
        localStorage.setItem(storageKey, bestVoice.name);
        localStorage.setItem(storageLang, bestVoice.lang);
        console.log(`‚úì Selected voice (filtered, SAVED FOREVER):`, bestVoice.name);
        return bestVoice;
    }
    
    // Last resort: Use default but log warning
    const defaultVoice = voices.find(v => v.lang.startsWith('en')) || voices[0];
    if (defaultVoice) {
        // Still save it as preference - FIXED
        localStorage.setItem(storageKey, defaultVoice.name);
        localStorage.setItem(storageLang, defaultVoice.lang);
    }
    console.warn('‚ö† Could not find preferred female voice, using:', defaultVoice?.name || 'default');
    return defaultVoice;
}

// Text-to-Speech with voice-only mode support and improved feminine voice
function speakText(text) {
    if (!text || text.trim() === '') {
        return;
    }
    
    if ('speechSynthesis' in window) {
        // Cancel any ongoing speech
        window.speechSynthesis.cancel();
        
        // Wait a bit before starting new speech for clarity
        setTimeout(() => {
            // Ensure voices are loaded (sometimes they load asynchronously)
            if (window.speechSynthesis.getVoices().length === 0) {
                window.speechSynthesis.onvoiceschanged = function() {
                    window.speechSynthesis.onvoiceschanged = null;
                    speakText(text); // Retry after voices are loaded
                };
                return;
            }
            
            const utterance = new SpeechSynthesisUtterance(text.trim());
            
            // Detect if text contains Hindi characters
            const isHindi = isHindiText(text);
            
            // Get the best available female voice based on language
            const selectedVoice = getBestFeminineVoice(isHindi);
            if (selectedVoice) {
                utterance.voice = selectedVoice;
                utterance.voiceURI = selectedVoice.voiceURI;
                if (isHindi) {
                    console.log('üîä Using Hindi female voice:', selectedVoice.name, `(${selectedVoice.lang})`);
                } else {
                    console.log('üîä Using English female voice:', selectedVoice.name, `(${selectedVoice.lang})`);
                }
            } else {
                console.warn('‚ö† No female voice found - using default voice');
            }
            
            // Optimize speech parameters for soft, feminine, human-like sound
            utterance.rate = 0.92;      // Slightly slower for natural, calm delivery
            utterance.pitch = 1.15;     // Slightly higher pitch for softer, more feminine tone
            utterance.volume = 0.92;    // Slightly lower volume for softer, gentler sound
            
            // Set language based on content detection
            if (isHindi) {
                utterance.lang = selectedVoice?.lang || 'hi-IN'; // Hindi (India)
            } else {
                utterance.lang = selectedVoice?.lang || 'en-US'; // English (US)
            }
            
            utterance.onstart = function() {
                isSpeaking = true;
                currentUtterance = utterance;
                
                // Show stop button when AI starts speaking
                const stopButton = document.getElementById('stopButton');
                if (stopButton) {
                    stopButton.style.display = 'block';
                }
                
                // Hide voice button when speaking (optional, for cleaner UI)
                const voiceButton = document.getElementById('voiceButton');
                if (voiceButton && voiceOnlyMode) {
                    voiceButton.style.display = 'none';
                }
                
                // Update UI to show AI is speaking
                const statusElement = document.getElementById('voiceStatus');
                if (statusElement) {
                    statusElement.textContent = 'üîä AI is speaking... (Click ‚èπÔ∏è to stop)';
                    statusElement.style.color = '#4caf50';
                }
                
                // Show speaking indicator on AI messages
                const aiMessages = document.querySelectorAll('[class*="from-primary/5"]');
                if (aiMessages.length > 0) {
                    const lastAiMessage = aiMessages[aiMessages.length - 1];
                    lastAiMessage.style.border = '2px solid #4caf50';
                }
            };
            
            utterance.onend = function() {
                isSpeaking = false;
                currentUtterance = null;
                
                // Hide stop button when AI finishes speaking
                const stopButton = document.getElementById('stopButton');
                if (stopButton) {
                    stopButton.style.display = 'none';
                }
                
                // Show voice button again
                const voiceButton = document.getElementById('voiceButton');
                if (voiceButton) {
                    voiceButton.style.display = 'block';
                }
                
                // Reset status
                const statusElement = document.getElementById('voiceStatus');
                if (statusElement) {
                    if (voiceOnlyMode && continuousVoiceMode) {
                        statusElement.textContent = 'üé§ Listening for your voice...';
                        statusElement.style.color = '#667eea';
                    } else {
                        statusElement.textContent = 'Ready';
                        statusElement.style.color = '#666';
                    }
                }
                
                // Remove speaking indicator
                const aiMessages = document.querySelectorAll('[class*="from-primary/5"]');
                aiMessages.forEach(msg => {
                    msg.style.border = '';
                });
                
                // Restart voice recognition in voice-only mode after AI finishes speaking
                if (voiceOnlyMode && continuousVoiceMode && !isRecording && !isProcessingMessage) {
                    setTimeout(() => {
                        if (voiceOnlyMode && !isRecording && !isProcessingMessage) {
                            startVoiceRecognition();
                        }
                    }, 500);
                }
            };
            
            utterance.onerror = function(event) {
                console.error('TTS Error:', event.error);
                isSpeaking = false;
                currentUtterance = null;
                
                // Hide stop button on error
                const stopButton = document.getElementById('stopButton');
                if (stopButton) {
                    stopButton.style.display = 'none';
                }
                
                // Show voice button again
                const voiceButton = document.getElementById('voiceButton');
                if (voiceButton) {
                    voiceButton.style.display = 'block';
                }
            };
            
            window.speechSynthesis.speak(utterance);
        }, 100);
    }
}

// Toggle Voice-Only Mode
function toggleVoiceOnlyMode() {
    voiceOnlyMode = document.getElementById('voiceOnlyMode').checked;
    const input = document.getElementById('messageInput');
    const sendButton = document.getElementById('sendButton');
    
    if (voiceOnlyMode) {
        // Enable voice-only mode
        input.disabled = true;
        input.style.opacity = '0.5';
        input.placeholder = 'Voice-only mode active - Use microphone to speak';
        sendButton.disabled = true;
        sendButton.style.opacity = '0.5';
        
        // Automatically enable continuous voice mode for voice-only
        continuousVoiceMode = true;
        
        // Start voice recognition automatically
        if (!isRecording && !isSpeaking && !isProcessingMessage) {
            setTimeout(() => {
                startVoiceRecognition();
            }, 500);
        }
        
        document.getElementById('voiceStatus').textContent = 'Voice-only mode active - Click mic to start!';
    } else {
        // Disable voice-only mode
        input.disabled = false;
        input.style.opacity = '1';
        input.placeholder = 'Type your message here or click the microphone to speak...';
        sendButton.disabled = false;
        sendButton.style.opacity = '1';
        
        if (isRecording) {
            recognition.stop();
            isRecording = false;
            updateVoiceButton();
        }
    }
}

// Start voice recognition with optimized settings
function startVoiceRecognition() {
    if (!recognition || isRecording || isSpeaking || isProcessingMessage) {
        return;
    }
    
    // Reset all tracking variables for fresh start
    lastFinalTranscript = '';
    pendingTranscript = '';
    lastUpdateTime = 0;
    
    // Configure recognition settings
    isRecording = true;
    continuousVoiceMode = voiceOnlyMode || continuousVoiceMode;
    recognition.continuous = continuousVoiceMode;
    
    // Set status
    document.getElementById('voiceStatus').textContent = voiceOnlyMode 
        ? 'üé§ Speak now - I\'m listening!' 
        : 'üé§ Listening... Speak now!';
    
    try {
        recognition.start();
        updateVoiceButton();
    } catch (e) {
        // Handle specific errors
        if (e.message && e.message.includes('already started')) {
            // Recognition already running, just update UI
            console.log('Recognition already active');
        } else {
            console.log('Recognition start error:', e);
            isRecording = false;
            updateVoiceButton();
            document.getElementById('voiceStatus').textContent = 'Error starting recognition. Try again.';
        }
    }
}

// Stop AI from speaking
function stopSpeaking() {
    if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
        isSpeaking = false;
        currentUtterance = null;
        
        // Hide stop button
        const stopButton = document.getElementById('stopButton');
        if (stopButton) {
            stopButton.style.display = 'none';
        }
        
        // Show voice button again
        const voiceButton = document.getElementById('voiceButton');
        if (voiceButton) {
            voiceButton.style.display = 'block';
        }
        
        // Update status
        const statusElement = document.getElementById('voiceStatus');
        if (statusElement) {
            if (voiceOnlyMode && continuousVoiceMode) {
                statusElement.textContent = '‚èπÔ∏è Speech stopped - Click mic to continue';
                statusElement.style.color = '#f44336';
                
                // Restart voice recognition after a brief delay
                setTimeout(() => {
                    if (voiceOnlyMode && !isRecording && !isProcessingMessage) {
                        statusElement.textContent = 'üé§ Listening for your voice...';
                        statusElement.style.color = '#667eea';
                        startVoiceRecognition();
                    }
                }, 1000);
            } else {
                statusElement.textContent = '‚èπÔ∏è Speech stopped';
                statusElement.style.color = '#f44336';
                
                // Reset to ready after a moment
                setTimeout(() => {
                    if (!isSpeaking) {
                        statusElement.textContent = 'Ready';
                        statusElement.style.color = '#666';
                    }
                }, 2000);
            }
        }
        
        // Remove speaking indicator from AI messages
        const aiMessages = document.querySelectorAll('[class*="from-primary/5"]');
        aiMessages.forEach(msg => {
            msg.style.border = '';
        });
        
        console.log('‚èπÔ∏è AI speech stopped by user');
    }
}

// Toggle Voice Recording
function toggleVoiceRecording() {
    if (!recognition) {
        alert('Speech recognition is not supported in your browser. Please use Chrome or Edge.');
        return;
    }
    
    // If AI is speaking, stop it first
    if (isSpeaking) {
        stopSpeaking();
        return;
    }
    
    if (isRecording) {
        // Stop recording
        recognition.stop();
        isRecording = false;
        document.getElementById('voiceStatus').textContent = voiceOnlyMode 
            ? 'Voice-only mode paused - Click mic to resume'
            : 'Stopped';
        lastFinalTranscript = '';
        pendingTranscript = '';
        if (autoSendTimeout) {
            clearTimeout(autoSendTimeout);
            autoSendTimeout = null;
        }
    } else {
        // Start recording
        startVoiceRecognition();
    }
}

function updateVoiceButton() {
    const btn = document.getElementById('voiceButton');
    if (isRecording) {
        btn.textContent = 'üî¥';
        btn.style.background = 'linear-gradient(135deg, #f44336 0%, #d32f2f 100%)';
    } else {
        btn.textContent = 'üé§';
        btn.style.background = 'linear-gradient(135deg, #667eea 0%, #764ba2 100%)';
    }
}

// Send Message with Real-Time Streaming
async function sendMessage() {
    const input = document.getElementById('messageInput');
    const message = input.value.trim();
    
    if (!message || isProcessingMessage) {
        return;
    }
    
    // Set processing flag
    isProcessingMessage = true;
    
    // Clear any pending auto-send timeout
    if (autoSendTimeout) {
        clearTimeout(autoSendTimeout);
        autoSendTimeout = null;
    }
    
    // Disable input while processing
    input.disabled = true;
    document.getElementById('sendButton').disabled = true;
    
    // Reset voice transcription tracking
    lastFinalTranscript = '';
    pendingTranscript = '';
    
    // Add user message to UI immediately
    addMessageToUI('user', message);
    input.value = '';
    
    // Check if streaming mode is enabled
    const streamingEnabled = document.getElementById('streamingMode').checked;
    
    if (streamingEnabled) {
        // Use real-time streaming from Gemini API
        await streamMessageRealTime(message);
    } else {
        // Use traditional non-streaming approach
        const typingId = addTypingIndicator();
        
        try {
            const response = await fetch('/conversation/send', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ message: message })
            });
            
            const data = await response.json();
            removeTypingIndicator(typingId);
            
            if (data.error) {
                const errorMsg = 'I apologize, but I encountered an error. Please try again.';
                addMessageToUI('assistant', errorMsg);
                speakText(errorMsg);
            } else {
                addMessageToUI('assistant', data.response);
                // Always speak the AI response (voice output)
                speakText(data.response);
            }
            isProcessingMessage = false; // Reset processing flag
        } catch (error) {
            console.error('Error:', error);
            removeTypingIndicator(typingId);
            const errorMsg = 'Sorry, I had trouble connecting. Please try again.';
            addMessageToUI('assistant', errorMsg);
            speakText(errorMsg); // Speak error message too
            isProcessingMessage = false; // Reset processing flag on error
        }
    }
    
    // Re-enable input and restart voice recognition if in continuous mode
    input.disabled = false;
    document.getElementById('sendButton').disabled = false;
    
    // Note: isProcessingMessage is reset in streamMessageRealTime or non-streaming path
    
    // Restart voice recognition if in continuous mode for real-time conversation
    if (continuousVoiceMode && isRecording) {
        setTimeout(() => {
            if (continuousVoiceMode && !isProcessingMessage) {
                input.focus();
                // Recognition will auto-restart via onend handler
            }
        }, 500);
    } else {
        input.focus();
    }
}

// Real-time streaming using EventSource (SSE)
async function streamMessageRealTime(message) {
    // Create streaming message container
    const container = document.getElementById('messagesContainer');
    const welcomeMsg = container.querySelector('.welcome-message');
    if (welcomeMsg) {
        welcomeMsg.remove();
    }
    
    // Remove any existing streaming message
    if (currentStreamingMessage) {
        currentStreamingMessage.remove();
    }
    
    const messageDiv = document.createElement('div');
    messageDiv.className = 'mb-4 p-4 rounded-xl bg-gradient-to-r from-primary/5 to-primary-dark/5 border-l-4 border-primary animate-fadeIn';
    messageDiv.innerHTML = `
        <div class="text-xs opacity-80 mb-2">
            <strong>ü§ñ SymbiONE</strong>
            <span class="text-[11px] opacity-60 ml-2">‚óè Streaming...</span>
        </div>
        <div class="text-[15px] leading-relaxed break-words border-r-2 border-primary pr-1 animate-pulse"></div>
    `;
    
    container.appendChild(messageDiv);
    currentStreamingMessage = messageDiv;
    
    const contentElement = messageDiv.querySelector('div:last-child');
    let fullResponse = '';
    
    try {
        // Use fetch with streaming
        const response = await fetch('/conversation/stream', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ message: message })
        });
        
        if (!response.ok) {
            throw new Error('Stream failed');
        }
        
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let buffer = '';
        
        while (true) {
            const { done, value } = await reader.read();
            
            if (done) {
                break;
            }
            
            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop(); // Keep incomplete line in buffer
            
            for (const line of lines) {
                if (line.startsWith('data: ')) {
                    try {
                        const data = JSON.parse(line.slice(6));
                        
                        if (data.chunk) {
                            fullResponse += data.chunk;
                            contentElement.textContent = fullResponse;
                            smoothScrollToBottom();
                        }
                        
                        if (data.done) {
                            // Streaming complete
                            const header = messageDiv.querySelector('div');
                            header.innerHTML = '<strong>ü§ñ SymbiONE</strong>';
                            const contentDiv = messageDiv.querySelector('div:last-child');
                            if (contentDiv) {
                                contentDiv.classList.remove('border-r-2', 'border-primary', 'pr-1', 'animate-pulse');
                            }
                            currentStreamingMessage = null;
                            
                            const finalResponse = data.full_response || fullResponse;
                            
                            // Mark processing as complete before speaking (so TTS can restart listening)
                            isProcessingMessage = false;
                            
                            // Always speak the AI response (voice output)
                            speakText(finalResponse);
                            
                            // In voice-only mode, restart listening will happen after TTS completes (via TTS onend callback)
                            
                            return;
                        }
                        
                        if (data.error) {
                            throw new Error(data.error);
                        }
                    } catch (e) {
                        console.error('Error parsing SSE data:', e);
                    }
                }
            }
        }
    } catch (error) {
        console.error('Streaming error:', error);
        contentElement.textContent = fullResponse || 'Sorry, I had trouble connecting. Please try again.';
        const header = messageDiv.querySelector('div');
        header.innerHTML = '<strong>ü§ñ SymbiONE</strong>';
        const contentDiv = messageDiv.querySelector('div:last-child');
        if (contentDiv) {
            contentDiv.classList.remove('border-r-2', 'border-primary', 'pr-1', 'animate-pulse');
        }
        currentStreamingMessage = null;
        isProcessingMessage = false; // Reset processing flag on error
    }
}

// Add message to UI
function addMessageToUI(role, content) {
    const container = document.getElementById('messagesContainer');
    
    // Remove welcome message if exists
    const welcomeMsg = container.querySelector('.text-center.text-gray-600.p-8');
    if (welcomeMsg) {
        welcomeMsg.remove();
    }
    
    const messageDiv = document.createElement('div');
    messageDiv.className = `mb-4 p-4 rounded-xl ${
        role === 'user' 
            ? 'bg-gradient-to-r from-primary/10 to-primary-dark/10 ml-auto max-w-[80%] border-l-4 border-primary-dark' 
            : 'bg-gradient-to-r from-primary/5 to-primary-dark/5 mr-auto max-w-[80%] border-l-4 border-primary'
    }`;
    messageDiv.innerHTML = `
        <div class="text-xs opacity-80 mb-2">
            <strong>${role === 'user' ? 'üë§ You' : 'ü§ñ SymbiONE'}</strong>
            ${role === 'assistant' ? '<span class="text-[11px] opacity-60 ml-2">‚óè Live</span>' : ''}
        </div>
        <div class="text-[15px] leading-relaxed break-words">${escapeHtml(content)}</div>
    `;
    
    container.appendChild(messageDiv);
    smoothScrollToBottom();
}

// Old simulated streaming function - kept as fallback if needed
// Real streaming is now handled by streamMessageRealTime() function

// Add typing indicator
function addTypingIndicator() {
    const container = document.getElementById('messagesContainer');
    const typingId = 'typing-' + Date.now();
    
    const typingDiv = document.createElement('div');
    typingDiv.id = typingId;
    typingDiv.className = 'mb-4 p-4 rounded-xl bg-gradient-to-r from-primary/5 to-primary-dark/5 border-l-4 border-primary opacity-70';
    typingDiv.innerHTML = `
        <div class="text-xs opacity-80 mb-2">
            <strong>ü§ñ SymbiONE</strong>
        </div>
        <div class="text-[15px] leading-relaxed break-words">
            <span class="inline-flex gap-1">
                <span class="animate-pulse" style="animation-delay: 0s;">.</span>
                <span class="animate-pulse" style="animation-delay: 0.2s;">.</span>
                <span class="animate-pulse" style="animation-delay: 0.4s;">.</span>
            </span>
        </div>
    `;
    
    container.appendChild(typingDiv);
    scrollToBottom();
    return typingId;
}

// Remove typing indicator
function removeTypingIndicator(typingId) {
    const indicator = document.getElementById(typingId);
    if (indicator) {
        indicator.remove();
    }
}

// Clear conversation
async function clearConversation() {
    if (!confirm('Are you sure you want to clear the conversation?')) {
        return;
    }
    
    try {
        await fetch('/conversation/clear', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            }
        });
        
        document.getElementById('messagesContainer').innerHTML = `
            <div class="welcome-message">
                <p>üëã Hi! I'm SymbiONE. I can help you with:</p>
                <ul>
                    <li>Career advice and job search tips</li>
                    <li>Wellness support during your job search</li>
                    <li>Understanding your skills and career path</li>
                    <li>Answering questions about finding jobs</li>
                </ul>
                <p>Start by saying hello or asking me anything!</p>
            </div>
        `;
    } catch (error) {
        console.error('Error clearing conversation:', error);
    }
}

// Quick message
function sendQuickMessage(message) {
    document.getElementById('messageInput').value = message;
    sendMessage();
}

// Scroll to bottom with smooth animation
function scrollToBottom() {
    const area = document.getElementById('conversationArea');
    area.scrollTop = area.scrollHeight;
}

// Smooth scroll to bottom
function smoothScrollToBottom() {
    const area = document.getElementById('conversationArea');
    area.scrollTo({
        top: area.scrollHeight,
        behavior: 'smooth'
    });
}

// Escape HTML
function escapeHtml(text) {
    const div = document.createElement('div');
    div.textContent = text;
    return div.innerHTML;
}

// Allow Enter key to send (Shift+Enter for new line)
document.getElementById('messageInput').addEventListener('keydown', function(e) {
    if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        sendMessage();
    }
});

// Auto-scroll on new messages with smooth animation
const observer = new MutationObserver(() => {
    setTimeout(smoothScrollToBottom, 100);
});
observer.observe(document.getElementById('messagesContainer'), { childList: true, subtree: true });

// Update connection status
function updateConnectionStatus(connected) {
    const statusDot = document.getElementById('statusDot');
    const statusText = document.getElementById('statusText');
    const statusContainer = document.getElementById('connectionStatus');
    
    if (connected) {
        statusDot.style.background = '#4caf50';
        statusText.textContent = 'Live';
        statusContainer.style.background = '#e8f5e9';
        statusContainer.style.color = '#2e7d32';
    } else {
        statusDot.style.background = '#ff9800';
        statusText.textContent = 'Connecting...';
        statusContainer.style.background = '#fff3e0';
        statusContainer.style.color = '#e65100';
    }
}

// Check connection status periodically
setInterval(async () => {
    try {
        const response = await fetch('/');
        updateConnectionStatus(response.ok);
    } catch (e) {
        updateConnectionStatus(false);
    }
}, 5000);

// Initialize on page load
window.addEventListener('load', () => {
    // Load and prepare voices for TTS
    if ('speechSynthesis' in window) {
        // Trigger voice loading (sometimes voices load asynchronously)
        window.speechSynthesis.getVoices();
        
        // Listen for when voices are loaded
        window.speechSynthesis.onvoiceschanged = () => {
            const voices = window.speechSynthesis.getVoices();
            console.log(`üì¢ Found ${voices.length} available voices`);
            
            // Log all available female voices for debugging
            const femaleVoices = voices.filter(v => {
                const name = v.name.toLowerCase();
                return name.includes('female') || 
                       name.includes('samantha') || 
                       name.includes('karen') || 
                       name.includes('victoria') ||
                       name.includes('zira') ||
                       name.includes('hazel') ||
                       name.includes('fiona');
            });
            
            if (femaleVoices.length > 0) {
                console.log('üë© Available female voices:', femaleVoices.map(v => v.name).join(', '));
            }
            
            // Initialize voice selection (will use saved voice if available, or select once and save forever)
            const selectedEnglishVoice = getBestFeminineVoice(false);
            const selectedHindiVoice = getBestFeminineVoice(true);
            
            if (selectedEnglishVoice) {
                console.log('‚úì English TTS Voice ready (FIXED - will never change):', selectedEnglishVoice.name, `(${selectedEnglishVoice.lang})`);
                console.log('  Voice settings: rate=0.92, pitch=1.15, volume=0.92');
                console.log('  ‚úì Voice preference saved to localStorage - will persist FOREVER across all sessions');
            } else {
                console.warn('‚ö† No English female voice found! Available voices:', voices.map(v => v.name).slice(0, 5).join(', '));
            }
            
            if (selectedHindiVoice) {
                console.log('‚úì Hindi TTS Voice ready (FIXED - will never change):', selectedHindiVoice.name, `(${selectedHindiVoice.lang})`);
            }
        };
        
        // Force voice reload (some browsers need this)
        setTimeout(() => {
            window.speechSynthesis.getVoices();
        }, 100);
    }
    
    // Check if voice-only mode should be enabled by default
    const voiceOnlyCheckbox = document.getElementById('voiceOnlyMode');
    if (voiceOnlyCheckbox && voiceOnlyCheckbox.checked) {
        toggleVoiceOnlyMode();
    } else {
        document.getElementById('messageInput').focus();
    }
});
</script>

<style>
.message {
    margin-bottom: 20px;
    padding: 15px;
    border-radius: 12px;
    animation: fadeIn 0.3s ease-in;
}

.user-message {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    margin-left: 20%;
    text-align: right;
}

.ai-message {
    background: white;
    color: #333;
    border: 2px solid #e0e0e0;
    margin-right: 20%;
}

.message-header {
    font-size: 12px;
    opacity: 0.8;
    margin-bottom: 8px;
}

.message-content {
    font-size: 15px;
    line-height: 1.6;
    word-wrap: break-word;
}

.welcome-message {
    text-align: center;
    color: #666;
    padding: 30px;
}

.welcome-message ul {
    text-align: left;
    display: inline-block;
    margin: 15px 0;
}

.typing-indicator {
    opacity: 0.7;
}

.typing-dots span {
    animation: blink 1.4s infinite;
    font-size: 20px;
}

.typing-dots span:nth-child(2) {
    animation-delay: 0.2s;
}

.typing-dots span:nth-child(3) {
    animation-delay: 0.4s;
}

@keyframes blink {
    0%, 100% { opacity: 0.2; }
    50% { opacity: 1; }
}

@keyframes fadeIn {
    from {
        opacity: 0;
        transform: translateY(10px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

@keyframes pulse {
    0%, 100% {
        opacity: 1;
        transform: scale(1);
    }
    50% {
        opacity: 0.7;
        transform: scale(1.1);
    }
}

.streaming-message {
    animation: fadeIn 0.3s ease-in;
}

.streaming-content {
    border-right: 2px solid #667eea;
    padding-right: 3px;
    animation: blink 1s infinite;
}

#conversationArea {
    scroll-behavior: smooth;
}

#conversationArea::-webkit-scrollbar {
    width: 8px;
}

#conversationArea::-webkit-scrollbar-track {
    background: #f1f1f1;
    border-radius: 10px;
}

#conversationArea::-webkit-scrollbar-thumb {
    background: #667eea;
    border-radius: 10px;
}

#conversationArea::-webkit-scrollbar-thumb:hover {
    background: #764ba2;
}

.quick-action-btn {
    padding: 10px 20px;
    background: white;
    border: 2px solid #667eea;
    color: #667eea;
    border-radius: 8px;
    font-size: 14px;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s;
}

.quick-action-btn:hover {
    background: #667eea;
    color: white;
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
}

#voiceButton:hover {
    transform: scale(1.1);
}

#sendButton:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
}

@media (max-width: 768px) {
    .user-message {
        margin-left: 10%;
    }
    
    .ai-message {
        margin-right: 10%;
    }
}
</style>
{% endblock %}

